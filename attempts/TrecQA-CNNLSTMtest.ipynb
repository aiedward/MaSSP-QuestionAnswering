{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrecQA-CNNLSTMtest.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1JqFysjkXbpshPkFoA2ggVCriFFZGYapL",
          "timestamp": 1530775508584
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "zfpNkdGUXcOT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "3aff7e9a-d995-40e7-e9a3-5d624b48695f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839527277,
          "user_tz": -420,
          "elapsed": 16378,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\r\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B-f7KbfOWJo7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "7ed8b2ff-1b36-40dd-ad51-b03cc45eb2ee",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839533374,
          "user_tz": -420,
          "elapsed": 2990,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wnw6OuurfPJX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## gensim word2vec preparation"
      ]
    },
    {
      "metadata": {
        "id": "fO3gUbIpfSgG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 748
        },
        "outputId": "5cfb5aaa-7502-4b4e-87fb-a548f0d8d7fc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839615540,
          "user_tz": -420,
          "elapsed": 11533,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U gensim\n",
        "#we use this for the word2vec representations of each word\n",
        "#remove if not using google colab. Instead, install from console"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/33/df6cb7acdcec5677ed130f4800f67509d24dbec74a03c329fcbf6b0864f0/gensim-3.4.0-cp36-cp36m-manylinux1_x86_64.whl (22.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 22.6MB 2.0MB/s \n",
            "\u001b[?25hRequirement not upgraded as not directly required: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/3d/5f3a9a296d0ba8e00e263a8dee76762076b9eb5ddc254ccaa834651c8d65/smart_open-1.6.0.tar.gz\n",
            "Requirement not upgraded as not directly required: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Requirement not upgraded as not directly required: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.5)\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/b7/a88a67002b1185ed9a8e8a6ef15266728c2361fcb4f1d02ea331e4c7741d/boto-2.48.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 16.1MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement not upgraded as not directly required: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/d3/b9fa3fb1c1e82a6eaf1b38b1daa8d8c0bf963a748aa417a36b437be59568/boto3-1.7.51-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 21.4MB/s \n",
            "\u001b[?25hRequirement not upgraded as not directly required: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.4.16)\n",
            "Requirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement not upgraded as not directly required: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement not upgraded as not directly required: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 15.0MB/s \n",
            "\u001b[?25hCollecting botocore<1.11.0,>=1.10.51 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/ba/f6c9220d87784a85f24a8f2425edccb2f330d15c304ea2373ed8206a03ca/botocore-1.10.51-py2.py3-none-any.whl (4.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.4MB 6.3MB/s \n",
            "\u001b[?25hRequirement not upgraded as not directly required: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.11.0,>=1.10.51->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Collecting docutils>=0.10 (from botocore<1.11.0,>=1.10.51->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 20.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/73/f1/9b/ccf93d4ba073b6f79b1ed9df68ab5ce048d8136d0efcf90b30\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.48.0 boto3-1.7.51 botocore-1.10.51 bz2file-0.98 docutils-0.14 gensim-3.4.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zETFCLXJffvT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "use gensim to get the word2vec representations of each word  \n",
        "reference here:  \n",
        "https://www.quora.com/How-do-you-extract-vectors-from-word2vec-given-a-word"
      ]
    },
    {
      "metadata": {
        "id": "d_p6oWAvoqp0",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "a0a8e23c-d4f0-4dd3-e190-bb14d07b9528",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839637810,
          "user_tz": -420,
          "elapsed": 20464,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors#, Word2Vec\n",
        "\n",
        "#currently using gensim's default word2vec pretrained model, trained on googlenews data. \n",
        "#todo: train on wikiqa if the results are crap. \n",
        "\n",
        "w2vmodel = KeyedVectors.load_word2vec_format('drive/Colab Notebooks/datasets/word2vec/GoogleNews-vectors-negative300-SLIM.bin.gz', binary=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3WDQwwa4qI-y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "word2vec first testing"
      ]
    },
    {
      "metadata": {
        "id": "QXCn6rzEqMrJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "bacf0344-b8f8-4cb9-ae6f-12133937ed63",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839638814,
          "user_tz": -420,
          "elapsed": 832,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# print(w2vmodel.similarity('woman','man'))\n",
        "wvdict = w2vmodel.wv.vocab\n",
        "#this is the list of all the words in the vocabulary"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "6HyQR9DHduTO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing input strings"
      ]
    },
    {
      "metadata": {
        "id": "yTkswavPBUsO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "36a3ec49-d167-4efe-8d1f-8ed09b4c9a78",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839639590,
          "user_tz": -420,
          "elapsed": 593,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hNJH983BqAdK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "`a.toks` contains the questions (repeat question lines correspond to the number of candidate answer sentences)  \n",
        "`b.toks` contains the answers. Each line is the answer to the question on the same line of `a.toks`  \n",
        "`id` contains the id of the question at that line in `a.toks`  \n",
        "`sim` contains the labels: for each block of repeated-questions: there is one line containing a `1` corresponding to the line in `b.toks` containing the correct answer to the same line in `a.toks`\n",
        "\n",
        "https://github.com/castorini/data/tree/master/WikiQA"
      ]
    },
    {
      "metadata": {
        "id": "rDxsDdT4W9lx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "acc32e71-c393-4590-9238-cf547cc8fa7c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839640605,
          "user_tz": -420,
          "elapsed": 879,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def read_data(path, readtype):\n",
        "  with open(path) as f:\n",
        "    lines = f.readlines()\n",
        "    \n",
        "  if readtype == \"questions\" or readtype == \"answers\":\n",
        "    return lines\n",
        "  elif readtype == \"labels\":\n",
        "    return [int(line) for line in lines]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TmcQBVaWF3sk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load the data"
      ]
    },
    {
      "metadata": {
        "id": "9o-OMzxmes6N",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "5aab5b31-37a1-4fa0-e239-29a19b789346",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839647804,
          "user_tz": -420,
          "elapsed": 6980,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "bigpath = \"drive/Colab Notebooks/datasets/QuestionAnswering/TrecQA/\"\n",
        "questions = read_data(bigpath+\"/train-all/a.toks\", \"questions\")\n",
        "answers = read_data(bigpath+\"/train-all/b.toks\", \"answers\")\n",
        "labels = read_data(bigpath+\"/train-all/sim.txt\", \"labels\")\n",
        "#question_ids = read_data(bigpath+\"/train/id.txt\", \"labels\")\n",
        "#questions"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vsDSeVa4mAzp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "ff5aed48-accc-4b8a-85bb-4391c40fd880",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839651902,
          "user_tz": -420,
          "elapsed": 1027,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "original_labels = labels\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "questions, questions_val, labels, labels_val = train_test_split(questions, original_labels, test_size = 0.2, random_state = 12)\n",
        "answers, answers_val, _, _ = train_test_split(answers, original_labels, test_size = 0.2, random_state = 12)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cNYJ5G3bpEIt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "test to see if the splits worked"
      ]
    },
    {
      "metadata": {
        "id": "RT1rVmOjpF1z",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "5745cbcb-2256-4c7c-ff72-1160381c2410",
        "executionInfo": {
          "status": "error",
          "timestamp": 1530812308988,
          "user_tz": -420,
          "elapsed": 886,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "p = 66088\n",
        "print(len(questions))\n",
        "print(questions[p])\n",
        "print(answers[p])\n",
        "print(labels[p])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42733\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bee2aa5b89ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m66088\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "mu43Qrp_hWTj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "9c5299cc-adaf-4713-a1de-96796e7900d8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839656292,
          "user_tz": -420,
          "elapsed": 771,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#resolve imbalanced data by oversampling positive results\n",
        "n_positiveduplicates = 10\n",
        "\n",
        "oversamp_questions = []\n",
        "oversamp_answers = []\n",
        "oversamp_labels = []\n",
        "for i in range(len(questions)):\n",
        "  if labels[i]==1:\n",
        "    for n in range(n_positiveduplicates):\n",
        "      oversamp_questions.append(questions[i])\n",
        "      oversamp_answers.append(answers[i])\n",
        "      oversamp_labels.append(labels[i])\n",
        "      \n",
        "      \n",
        "questions += oversamp_questions\n",
        "answers += oversamp_answers\n",
        "labels += oversamp_labels"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MgEaCfaOin4h",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "59f6c79b-ad53-4b6a-d809-5fbc3acd6845",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839681866,
          "user_tz": -420,
          "elapsed": 711,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "questions, answers, labels = shuffle(questions, answers, labels)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FXnePrC9PGrb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### creating one-hot labels"
      ]
    },
    {
      "metadata": {
        "id": "Xg2CQ9NRPKuL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "0c961ee8-9323-4230-dcaa-a8e244f1cd1e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839701314,
          "user_tz": -420,
          "elapsed": 688,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gLedyG96PQct",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "9c19e7c6-a45d-4393-acfb-1a026548ea28",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839702562,
          "user_tz": -420,
          "elapsed": 693,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "labels_np = np.array(labels)\n",
        "labels_np = np.expand_dims(labels_np, axis=1)\n",
        "\n",
        "onehot = OneHotEncoder(n_values = 2)\n",
        "onehot.fit(labels_np)\n",
        "labels_np = onehot.transform(labels_np)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ekv8FyqirInq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "c85951a8-ddab-4319-8e00-436ed621cb8e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839705372,
          "user_tz": -420,
          "elapsed": 643,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "val_labels_np = np.array(labels_val)\n",
        "val_labels_np = np.expand_dims(val_labels_np, axis=1)\n",
        "\n",
        "onehot.fit(val_labels_np)\n",
        "val_labels_np = onehot.transform(val_labels_np)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t8v6mW3xswrR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### preparing word-level sequence embedding"
      ]
    },
    {
      "metadata": {
        "id": "cLbh0COIs4lN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is to prepare for the Embedding layer\n",
        "\n",
        "1. concatenate questions and answers into a list of `[question | answer]` pairs. This is a list of sequences.  \n",
        "2. find max sequence length from this list  \n",
        "3. the vocab size of the google news word2vec is 3 million words, the number of features is 300\n",
        "\n",
        "The embedding_matrix:\n",
        "1. let each word in `w2vmodel.wv.vocab.keys()` have an index\n",
        "2. concatenate axis=1 all the word vectors in the vocabulary into embedding_matrix\n",
        "3. then turn each string sequence into an array of numbers (each number represents the index of that word in the vocab)\n",
        "4. pass the string sequences into the .fit as training input. The shape of this input should be (n_seqs, max_seq_length, n_features)\n",
        "5. the embedding matrix will be the weights in the Embedding layer"
      ]
    },
    {
      "metadata": {
        "id": "DH96kKR08lNS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "8c32e41f-6056-4ab3-e585-1b628b0cbf71",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839710537,
          "user_tz": -420,
          "elapsed": 896,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "vocab_size = 299567+1 #this is the SLIMmed googlenews w2v model's vocab count. #the last item is the 'all-zeroes' word vector, used for words that aren't in the w2vmodel"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mFX2hmOP64Bb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "b51eccfa-98e0-424b-907c-e35a227e1eb1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839727907,
          "user_tz": -420,
          "elapsed": 4187,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#make embedding matrix\n",
        "embedding_matrix = np.zeros((vocab_size, 300))\n",
        "for i in range(len(wvdict)):\n",
        "    embedding_vector = w2vmodel.wv[w2vmodel.wv.index2word[i]]\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    \n",
        "  "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nORIwkiQ_S1O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### define some functions to preprocess data (both train and test)"
      ]
    },
    {
      "metadata": {
        "id": "Hmf60uv2_bNj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "ce34a6c2-d830-4d94-e832-159759c82ddb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839734847,
          "user_tz": -420,
          "elapsed": 949,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def SEQ_max_length(sequences):\n",
        "  return max( [len(qa.split()) for qa in sequences] )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EkDys4HMD4D-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "15115c63-8de3-4e33-e293-f46f0c617390",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839744435,
          "user_tz": -420,
          "elapsed": 9017,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qp2-JrzdEVcT",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "887ce429-201b-4051-c567-07740a8e055f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839751970,
          "user_tz": -420,
          "elapsed": 768,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def SEQ_token_and_pad(sequences, max_seq_length):\n",
        "  encoded_seqs = []\n",
        "  for qa in sequences:\n",
        "    encoded_qa = []\n",
        "    tokenized_qa = qa.split()\n",
        "    for word in tokenized_qa:\n",
        "      index_to_append = vocab_size - 1\n",
        "      \n",
        "      if word in wvdict.keys():\n",
        "        index_to_append = w2vmodel.vocab[word].index\n",
        "      encoded_qa.append(index_to_append)\n",
        "    \n",
        "    encoded_seqs.append(encoded_qa)\n",
        "    \n",
        "  \n",
        "  padded_seqs = pad_sequences(encoded_seqs, maxlen = max_seq_length, padding=\"post\", value = vocab_size - 1)\n",
        "  return padded_seqs"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WR3lQtUY7BCC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Performing the necessary preprocessing on our data using our functions"
      ]
    },
    {
      "metadata": {
        "id": "UTbIE6T37AQl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "e7905547-8247-41ad-b2cf-05ff8185f9a4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839761550,
          "user_tz": -420,
          "elapsed": 4848,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "max_question_length = SEQ_max_length(questions)\n",
        "max_answer_length = SEQ_max_length(answers)\n",
        "val_max_question_length = SEQ_max_length(questions_val)\n",
        "val_max_answer_length = SEQ_max_length(answers_val)\n",
        "max_hidden_length = max(max_question_length, max_answer_length, val_max_question_length, val_max_answer_length)\n",
        "\n",
        "#version 1: getting separate questions and answers vectors (but still encoded in index form, not in pure word vector form)\n",
        "padded_questions = SEQ_token_and_pad(questions, max_hidden_length)\n",
        "padded_answers = SEQ_token_and_pad(answers, max_hidden_length)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Lh6NSZwqTGX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "do the same preprocessing on our validation set"
      ]
    },
    {
      "metadata": {
        "id": "UYJ7ISTqqU63",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "73cb18e6-c69f-4edd-9c65-9ebb182c7ee5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839766994,
          "user_tz": -420,
          "elapsed": 1044,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "val_padded_questions = SEQ_token_and_pad(questions_val, max_hidden_length)\n",
        "val_padded_answers = SEQ_token_and_pad(answers_val, max_hidden_length)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oc-VoTmpsdmc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model building and training"
      ]
    },
    {
      "metadata": {
        "id": "C4nQNUEvjSqP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Guesswork and experimentation"
      ]
    },
    {
      "metadata": {
        "id": "y9M2Frrx0Wrz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "*If i'm doing the implementation in the 1506.06490 paper*  \n",
        "**Todo**: \n",
        "\n",
        "- find length of the longest question and longest answer\n",
        "- use these maxes for padding to shorter sentences\n",
        "- in one big model, build 2 separate convnet submodels, one for questions, one for answers\n",
        "- concatenate the outputs for the questions and answers convnets, and we obtain the **joint representation** `p` of each question-answer pair.\n",
        "\n",
        "Each of these learned joint pairs is a single **timestep** in the LSTM part. We learn the sequence and semantic relationships between each answer-candidate sentence in the context paragraph, not between the words themselves. (the word-level patterns are learned in the Conv stage already)\n",
        "\n",
        "for the LSTM stage, padding instead involves adding dummy qa pairs for each timestep without an answer. The max number of answer candidates in the dataset (and possible qa pairs, per question) is 30, so any Qs with fewer than 30 answer sentences will be padded with dummy pairs.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DnGBC-R5EVCt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "*my own simple-ass idea*  \n",
        "**Todo:**\n",
        "\n",
        "version 0a: `shit lstm model copped from some blog`  \n",
        "https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
        "\n",
        "version 0b: `with learning rate, and fixed word tokenizations`\n",
        "\n",
        "version 1a: `separate LSTM for question and answer, then Concatenate into a hidden layer which then is fed into classifier/Dense/whatever`\n",
        "\n",
        "version 1b: `no LSTM for question and answer. Using Functional API. WORKS but OVERFITS.`"
      ]
    },
    {
      "metadata": {
        "id": "SgNENhwKWZ5A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Giang's idea"
      ]
    },
    {
      "metadata": {
        "id": "sdsWQTH8S57x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Giang's idea:\n",
        "\n",
        "`doc question  \n",
        "input_1 = Input(...)  \n",
        "...  \n",
        "output_1 = ...\n",
        "\n",
        "\n",
        "doc answer  \n",
        "input_2 = Input(...)  \n",
        "...  \n",
        "output_2 = ...\n",
        "\n",
        "input_2 = Embedding(vocab_size, 300, weights = [embedding_matrix], input_length = max_answer_length, trainable=False)  \n",
        "  \n",
        "output_2 = LSTM(100)(input_reshape_2)\n",
        "\n",
        "hidden = Concatenate()([output_1, output_2])\n",
        "classifier = Dense(1, activation=\"sigmoid\")(hidden)\n",
        "`"
      ]
    },
    {
      "metadata": {
        "id": "_kxBIRzPT1Fd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "2414ffea-9b2e-4d10-d230-00fa149b112b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530839861027,
          "user_tz": -420,
          "elapsed": 3205,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Concatenate, LSTM, Dense, Conv1D, MaxPooling1D, Dropout\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "#using keras functional api\n",
        "\n",
        "qumodel_input = Input(shape = (max_hidden_length,), name=\"questionsMainInput\")\n",
        "qumodel_embed = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_hidden_length, trainable=False)(qumodel_input)\n",
        "qumodel_parse = Conv1D(32, 2)(qumodel_embed)\n",
        "qumodel_parse = Dropout(0.29)(qumodel_parse)\n",
        "qumodel_parse = MaxPooling1D(pool_size = 2)(qumodel_parse)\n",
        "\n",
        "ansmodel_input = Input(shape = (max_hidden_length,), name=\"answersMainInput\")\n",
        "ansmodel_embed = Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_hidden_length, trainable=False)(ansmodel_input)\n",
        "ansmodel_parse = Conv1D(32,2)(ansmodel_embed)\n",
        "ansmodel_parse = Dropout(0.29)(ansmodel_parse)\n",
        "ansmodel_parse = MaxPooling1D(pool_size = 2)(ansmodel_parse)\n",
        "\n",
        "combinedmodel = Concatenate()([qumodel_parse, ansmodel_parse])\n",
        "print(combinedmodel.shape)\n",
        "\n",
        "lstmcombinedmodel = LSTM(100)(combinedmodel)\n",
        "classifier = Dense(32, activation='relu')(lstmcombinedmodel)\n",
        "classifier = Dense(16, activation='relu')(classifier)\n",
        "classifier = Dense(2, activation='softmax')(classifier)\n",
        "\n",
        "final_model = Model(inputs = [qumodel_input, ansmodel_input], outputs = classifier)\n",
        "\n",
        "final_model.compile(loss = 'categorical_crossentropy', optimizer = Adam(lr = 0.003), metrics=['accuracy'])\n",
        "print(final_model.summary())"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 29, 64)\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "questionsMainInput (InputLayer) (None, 60)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "answersMainInput (InputLayer)   (None, 60)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 60, 300)      89870400    questionsMainInput[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 60, 300)      89870400    answersMainInput[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 59, 32)       19232       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 59, 32)       19232       embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 59, 32)       0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 59, 32)       0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 29, 32)       0           dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 29, 32)       0           dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 29, 64)       0           max_pooling1d_1[0][0]            \n",
            "                                                                 max_pooling1d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 100)          66000       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 32)           3232        lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 16)           528         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 2)            34          dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 179,849,058\n",
            "Trainable params: 108,258\n",
            "Non-trainable params: 179,740,800\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hfOWBI3J7s8N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fit the chosen model"
      ]
    },
    {
      "metadata": {
        "id": "SgxZXbGTFVRC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Severely punish \"no\" answers because that's just lazy. The network should at least try to guess \"yes\" or \"1\" on at least some questions, and not settle for a 88% accuracy by answering no to everything.\n",
        "\n",
        "add class_weights and try:"
      ]
    },
    {
      "metadata": {
        "id": "95zZqZ8aFG6d",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7dfb5b14-4347-4223-995f-4d79af02722b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530778807439,
          "user_tz": -420,
          "elapsed": 694,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(labels), labels)\n",
        "class_weights\n",
        "#class_weights = np.array([0.5, 24.])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.56809674, 4.17124785])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "zw80lLlTidUs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "d4807089-01aa-49a9-ebd4-3cd8669b27f4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530815856256,
          "user_tz": -420,
          "elapsed": 716,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpointer = ModelCheckpoint(filepath=\"drive/Colab Notebooks/checkpts/weights.{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}.hdf5\", monitor = \"val_acc\", save_best_only = True, mode=\"max\")\n",
        "callback_list = [checkpointer]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kd34uHOvMRE1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "7c7bbfe9-7b9c-44e4-8256-cc748be55f25"
      },
      "cell_type": "code",
      "source": [
        "#final_model.fit([padded_questions, padded_answers], labels, epochs=5, batch_size=128, verbose=1, class_weight = class_weights, validation_split=0.2)\n",
        "\n",
        "#model.fit([padded_questions, padded_answers], labels, batch_size=32,\n",
        " #         epochs=20, validation_split=0.1, class_weight = class_weights)\n",
        "  \n",
        "final_model.fit([padded_questions, padded_answers], labels_np, \n",
        "                epochs=30, \n",
        "                batch_size=128, \n",
        "                verbose=1, \n",
        "                validation_data = ([val_padded_questions, val_padded_answers], val_labels_np),\n",
        "                callbacks = callback_list\n",
        "               )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 94283 samples, validate on 10684 samples\n",
            "Epoch 1/30\n",
            "88064/94283 [===========================>..] - ETA: 4s - loss: 0.4941 - acc: 0.7686"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "94283/94283 [==============================] - 71s 755us/step - loss: 0.4907 - acc: 0.7706 - val_loss: 0.4937 - val_acc: 0.7005\n",
            "Epoch 2/30\n",
            "54784/94283 [================>.............] - ETA: 32s - loss: 0.4063 - acc: 0.8190"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "94283/94283 [==============================] - 77s 812us/step - loss: 0.3936 - acc: 0.8267 - val_loss: 0.4253 - val_acc: 0.7736\n",
            "Epoch 3/30\n",
            "41600/94283 [============>.................] - ETA: 45s - loss: 0.3491 - acc: 0.8500"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "94283/94283 [==============================] - 76s 804us/step - loss: 0.3393 - acc: 0.8557 - val_loss: 0.4306 - val_acc: 0.7999\n",
            "Epoch 4/30\n",
            "37120/94283 [==========>...................] - ETA: 50s - loss: 0.3019 - acc: 0.8777"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "94283/94283 [==============================] - 76s 809us/step - loss: 0.2959 - acc: 0.8792 - val_loss: 0.3842 - val_acc: 0.8225\n",
            "Epoch 5/30\n",
            "35584/94283 [==========>...................] - ETA: 52s - loss: 0.2713 - acc: 0.8906"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "94283/94283 [==============================] - 77s 812us/step - loss: 0.2605 - acc: 0.8961 - val_loss: 0.3767 - val_acc: 0.8326\n",
            "Epoch 6/30\n",
            " 9856/94283 [==>...........................] - ETA: 1:24 - loss: 0.2472 - acc: 0.9018"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "taVjH9p75a2y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "final_model.save(\"cnnlstm-rollercoaster.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7B1ScOFP1bS3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ...or load a checkpoint hdf5\n",
        "\n",
        "(must compile model first!, then load in the weights hdf5 and start predicting/continue fitting)"
      ]
    },
    {
      "metadata": {
        "id": "iZXQ2Mw11dbA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "d2048011-6ce8-4abb-d48a-e77e6b679364",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530840278089,
          "user_tz": -420,
          "elapsed": 17544,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "checkptname = \"weights.24-0.35-0.90.hdf5\"\n",
        "final_model.load_weights(\"drive/Colab Notebooks/checkpts/\"+checkptname)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZslLPJeSN1a1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Testing the trained model"
      ]
    },
    {
      "metadata": {
        "id": "9TfGtdtoOdbw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Preparing the test data"
      ]
    },
    {
      "metadata": {
        "id": "RKf_rtGrN4fO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "effad48b-a044-47f9-9de1-5aee24864cab",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530840397682,
          "user_tz": -420,
          "elapsed": 5237,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# test_questions = [\"Where was Tuan born\",\"Where was Tuan born\",\"Where was Tuan born\",\"Where was Tuan born\"]\n",
        "# test_answers = [\"Pigs dogs cats\",\"Boo\",\"Candy balls cake\", \"Tuan was born in Vietnam\"]\n",
        "# test_labels = [0, 0, 0, 1]\n",
        "\n",
        "\n",
        "\n",
        "test_questions = read_data(bigpath+\"/raw-test/a.toks\", \"questions\")\n",
        "test_answers = read_data(bigpath+\"/raw-test/b.toks\", \"answers\")\n",
        "test_labels = read_data(bigpath+\"/raw-test/sim.txt\", \"labels\")\n",
        "# question_ids = read_data(bigpath+\"/dev/id.txt\", \"labels\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7cclUTguOx0e",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "0106146f-ffa2-4d26-d795-759e7e92b0d5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530840411662,
          "user_tz": -420,
          "elapsed": 822,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#test_seqs, max_test_seq_length = SEQ_make_qa_sequences_list(test_questions, test_answers)\n",
        "padded_test_questions = SEQ_token_and_pad(test_questions, max_hidden_length)\n",
        "padded_test_answers = SEQ_token_and_pad(test_answers, max_hidden_length)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XX-Hb8hvPPTU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Predicting some q, a pairs"
      ]
    },
    {
      "metadata": {
        "id": "u1oZhJXePMLL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "779a167a-f0ba-43a4-f9bb-771e820259df",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530840421489,
          "user_tz": -420,
          "elapsed": 1611,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "test_preds = final_model.predict_on_batch([padded_test_questions, padded_test_answers])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8VAqYQZ-YWTe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6bf26b0e-1833-4940-bb8e-80f30869e327",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530761445690,
          "user_tz": -420,
          "elapsed": 907,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(test_preds)\n",
        "np.argmax(test_preds*1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.9997854e-01 2.1408780e-05]\n",
            " [9.9997807e-01 2.1898602e-05]\n",
            " [9.9996340e-01 3.6599067e-05]\n",
            " [9.9997723e-01 2.2740214e-05]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "E3NEhF84Rgnq",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "10151cf1-c8a6-49bd-e4ad-fe61af8509e8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1530840695236,
          "user_tz": -420,
          "elapsed": 660,
          "user": {
            "displayName": "Nam Anh Dinh",
            "photoUrl": "//lh5.googleusercontent.com/-bx5rUgj7X3U/AAAAAAAAAAI/AAAAAAAAAT8/kPBiiqWYU3s/s50-c-k-no/photo.jpg",
            "userId": "105485123729788675852"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "i=77 #test example to check\n",
        "\n",
        "# print(padded_test_seqs[1])\n",
        "# print(padded_test_seqs[16])\n",
        "\n",
        "print(test_preds[i])\n",
        "print(test_questions[i])\n",
        "print(test_answers[i])\n",
        "print(\"correct label: \"+str(test_labels[i]))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9.9959809e-01 4.0195804e-04]\n",
            "who is the president or chief executive of amtrak ?\n",
            "\n",
            "amtrak is offering vouchers , instead of refunds on the current trip , to give itself a second chance to woo the customer .\n",
            "\n",
            "correct label: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TQlY2QuGWDsL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}